"Name","Notes","classifier","accuracy","macro avg.f1-score","macro avg.precision","macro avg.recall"
"CodeLlama-70b-Instruct-hf-apps_competition_207_LR","-","LR","0.8676470588235294","0.8640906062624916","0.8869767441860466","0.8611111111111112"
"CodeLlama-70b-Instruct-hf-apps_introductory_207_LR","-","LR","0.8405797101449275","0.8384074941451991","0.8435344827586206","0.8365709459459459"
"CodeLlama-70b-Instruct-hf-apps_interview_207_LR","-","LR","0.8904109589041096","0.8868217054263565","0.9053945249597424","0.8814393939393939"
"Mixtral-8x7B-Instruct-v0.1-apps_competition_207_LR","-","LR","0.9156626506024096","0.9138621200889548","0.9154761904761904","0.9125295508274232"
"Mixtral-8x7B-Instruct-v0.1-apps_interview_207_LR","-","LR","0.896969696969697","0.8967269246345864","0.9","0.8967087863649721"
"Mixtral-8x7B-Instruct-v0.1-apps_introductory_207_LR","-","LR","0.9156626506024096","0.9138621200889548","0.9154761904761904","0.9125295508274232"
"gemma-7b-it-apps_competition_207_LR","-","LR","0.8536585365853658","0.8528708133971292","0.8521168753726893","0.8546546546546547"
"gemma-7b-it-apps_interview_207_LR","-","LR","0.9036144578313252","0.9018912529550828","0.9018912529550828","0.9018912529550828"
"gemma-7b-it-apps_introductory_207_LR","-","LR","0.8072289156626506","0.8069767441860465","0.8217261904761904","0.8160818713450293"