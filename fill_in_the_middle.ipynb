{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, json\n",
    "import random, os\n",
    "from utils_batch import InfillingModel\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default=\"code_bert/codebert_competition_test.jsonl\")\n",
    "parser.add_argument('--perturbations', default=4, type=int)\n",
    "parser.add_argument('--mask_lines', default=8, type=int)\n",
    "parser.add_argument(\"--gpu\", type=str, default=\"2\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"facebook/incoder-1B\")\n",
    "parser.add_argument(\"--run\", type=str, default= \"1\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "output_file = f'FIM/{args.dataset.split(\"/\")[1][:-6]}_FIM_human_{args.run}_line_{args.mask_lines}_per_{args.perturbations}.jsonl'\n",
    "print(output_file)\n",
    "with open(args.dataset, 'r') as f:\n",
    "    dataset = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "print(args)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_properties(0).total_memory)\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "if args.model_name == 'facebook/incoder-6B':\n",
    "    args.half = True\n",
    "else:\n",
    "    args.half = False\n",
    "infilling_model = InfillingModel(model_name=args.model_name, cuda=True, half=args.half, device=device)\n",
    "\n",
    "\n",
    "def find_all(substring, string):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = string.find(substring, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(substring)\n",
    "\n",
    "def mask_code(pasrsed_codes, mask_lines = args.mask_lines):\n",
    "    for _ in range(mask_lines):\n",
    "        positions = list(find_all(substring='\\n', string=pasrsed_codes))\n",
    "        if positions == []:\n",
    "            positions = list(find_all(substring=':', string=pasrsed_codes))\n",
    "        if len(positions) < 2:\n",
    "                continue # cornor case in which there is no \\n and only one ':'\n",
    "        mask_start = random.choice( range(len( (positions)) -1 ) )\n",
    "        mask_start_position = positions[mask_start]\n",
    "        mask_end_position = positions[mask_start+1]\n",
    "        pasrsed_codes = pasrsed_codes[:mask_start_position] +  '<insert>' + pasrsed_codes[mask_end_position:]\n",
    "    pasrsed_codes_masked = pasrsed_codes\n",
    "    return pasrsed_codes_masked #, mask_end_position - mask_start_position\n",
    "\n",
    "def norm_inserts_num(pasrsed_code_norm):\n",
    "    max_num = 0\n",
    "    for i, x in enumerate(pasrsed_code_norm):\n",
    "        if len(list(find_all(substring='<insert>', string=x))) > max_num:\n",
    "            max_num = len(list(find_all(substring='<insert>', string=x)))\n",
    "            id = i\n",
    "\n",
    "    new_res = []\n",
    "    for x in pasrsed_code_norm:\n",
    "        if len( list( find_all(substring='<insert>', string=x) ) ) < max_num:\n",
    "            new_res.append( pasrsed_code_norm[id] )\n",
    "        else:\n",
    "            new_res.append( x )\n",
    "    return new_res\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, 'r') as f:\n",
    "        finished = [json.loads(line) for line in f.readlines()]\n",
    "    dataset = dataset[len(finished):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d59798cd1414e2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "###### fill_in_middle_gold and fill_in_middle_parsed ######\n",
    "for idx, ins in tqdm.tqdm(enumerate(dataset), total = len(dataset)):\n",
    "\n",
    "    gold_completion_all = []\n",
    "    if len(ins['code']) < 3200:\n",
    "        for _ in range(args.perturbations):\n",
    "            gold_codes_masked = mask_code(ins['code'], mask_lines=args.mask_lines)\n",
    "            gold_completion_all.append(gold_codes_masked[:3200])\n",
    "\n",
    "        gold_completion_all = norm_inserts_num(gold_completion_all)\n",
    "        parts_batch = [example.split(\"<insert>\") for example in gold_completion_all]\n",
    "        fill_in_middle_gold = infilling_model.batched_infill(parts_batch, max_to_generate=16*args.mask_lines, temperature=0.7)\n",
    "        ins['FIM_code'] = fill_in_middle_gold\n",
    "    else:\n",
    "        ins['FIM_code'] = ['token exceeds 3200']\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write(json.dumps(ins) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715f275e6434584"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
